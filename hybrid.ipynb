{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rAH0eXL5ny9W"},"outputs":[],"source":["\n","#!pip install pmdarima\n","\n","\n","\n","import sys,os\n","\n","import pandas as pd\n","import numpy as np \n","\n","from matplotlib import pyplot as plt \n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n","import math\n","\n","from pmdarima import auto_arima\n","from pmdarima import pipeline\n","from pmdarima import model_selection\n","from pmdarima import preprocessing as ppc\n","from pmdarima import arima\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM,Bidirectional\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","from contextlib import contextmanager\n","@contextmanager\n","def suppress_stdout():\n","    with open(os.devnull, \"w\") as devnull:\n","        old_stdout = sys.stdout\n","        sys.stdout = devnull\n","        try:  \n","            yield\n","        finally:\n","            sys.stdout = old_stdout\n","     \n","###################################################################################################################################################\n","df_metrics=pd.DataFrame()\n","def metrics(test,prediction_test,final):\n","    df_metrics.at[0,\"MAE_ARIMA\"]=(mean_absolute_error(test,prediction_test))\n","    df_metrics.at[0,\"MAE_Hybrid\"]=(mean_absolute_error(test,final))\n","    df_metrics.at[0,\"RMSE_ARIMA\"]=(math.sqrt(mean_squared_error(test, prediction_test)))\n","    df_metrics.at[0,\"RMSE_Hybrid\"]=(math.sqrt(mean_squared_error(test, final)))\n","    df_metrics.at[0,\"MSE_ARIMA\"]=(mean_squared_error(test,prediction_test))\n","    df_metrics.at[0,\"MSE_Hybrid\"]=(mean_squared_error(test,final))\n","    df_metrics.at[0,\"MAPE_ARIMA\"]=(mean_absolute_percentage_error(test,prediction_test))\n","    df_metrics.at[0,\"MAPE_Hybrid\"]=(mean_absolute_percentage_error(test,final))\n","    return df_metrics\n","\n","###################################################################################################################################################\n","def get_bilstm_dataframe(df,train,test):\n","  df_pred_train=train.to_frame()\n","  df_pred_test=test.to_frame()\n","  df_pred_test.columns=df_pred_train.columns\n","  df_temp=pd.concat([df_pred_train,df_pred_test],ignore_index=True)\n","  a=df.products_quantity.values-df_temp.values\n","  a=pd.DataFrame(df.products_quantity)\n","  df_bilstm=a-df_temp.values\n","  df_bilstm=df_bilstm.reset_index(drop=True)\n","  df_bilstm['price_per_unit']=df['price_per_unit'].to_numpy()\n","  return df_bilstm   \n","\n","###################################################################################################################################################\n","def plot_arima(df_data,prediction_test,prediction_train):\n","    #plot arima predicition\n","    fig, ax = plt.subplots(1, 1, figsize=(25, 10))\n","    ax.plot(df_data)\n","    ax.plot(prediction_test)\n","    ax.plot(prediction_train)\n","    plt.axhline(0,color=\"black\",alpha=0.3) #x-axis line\n","    plt.show()\n","\n","def plot_loss(history):\n","    #plot Bilstm train-val loss\n","    fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n","    plt.plot(history.history['loss'], label='Training loss')\n","    plt.plot(history.history['val_loss'], label='Validation loss')\n","    plt.legend()\n","    plt.show()\n","def plot_bilstm(df_bilstm,df_bilstm_prdictions):\n","    #plot Bilstm predictions\n","    fig, ax = plt.subplots(1, 1, figsize=(25, 10))\n","    ax.plot(df_bilstm.products_quantity)\n","    ax.plot(df_bilstm_prdictions)\n","    plt.axhline(0,color=\"black\",alpha=0.3) #x-axis line\n","    plt.show()\n","\n","###################################################################################################################################################\n","def Arima(df):\n","  d=arima.ndiffs(df.products_quantity)\n","  df_data = df.products_quantity.to_numpy()\n","  train, test = model_selection.train_test_split(df_data, train_size=int(len(df_data)*0.8))\n","\n","  # create a pipeline with multiple stages... the  dataset is\n","  # seasonal, so we'll include a FourierFeaturizer so we can fit it without\n","  # seasonality\n","\n","  with suppress_stdout():\n","    pipe = pipeline.Pipeline([\n","        (\"fourier\", ppc.FourierFeaturizer(m=52, k=26)),\n","        (\"arima\", auto_arima(train,start_p=0, d=d, start_q=0, \n","                                          max_p=7, max_d=1, max_q=7,\n","                                          seasonal=False, \n","                                          error_action='ignore',trace = True,\n","                                          supress_warnings=False,stepwise = True))])\n","    pipe.fit(train)\n","  \n","\n","  prediction_test= pipe.predict(n_periods=len(test))\n","  prediction_train=pipe.predict_in_sample()\n","\n","\n","\n","  resid=train-pipe.predict_in_sample()\n","  \n","  df_bilstm=get_bilstm_dataframe(df,prediction_train,prediction_test)\n","\n","  return prediction_test,df_bilstm,prediction_train,test,pipe\n","\n","###################################################################################################################################################\n","def BiLSTM(df_bilstm):\n","   \n","\n","    size=int(len(df_bilstm)*0.8)\n","    df_for_training=df_bilstm[:size]\n","    \n","\n","    #LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n","    # normalize the dataset\n","    scaler = StandardScaler()\n","    scaler = scaler.fit(df_for_training)\n","    df_for_training_scaled = scaler.transform(df_for_training)\n","\n","\n","    \n","    trainX = []\n","    trainY = []\n","\n","    n_future = 1   # Number of days we want to look into the future based on the past days.\n","    n_past = 3  # Number of past days we want to use to predict the future.\n","\n","\n","    #Reformat input data into a shape: (n_samples x timesteps x n_features)\n","    for n in range(n_past, len(df_for_training_scaled) - n_future +1):\n","        trainX.append(df_for_training_scaled[n - n_past:n, 0:df_for_training.shape[1]])\n","        trainY.append(df_for_training_scaled[n + n_future - 1:n + n_future, 0])\n","\n","    trainX, trainY = np.array(trainX), np.array(trainY)\n","\n","\n","\n","\n","    # define the model\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(32, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=False)))\n","    #model.add(Bidirectional(LSTM(4, activation='relu', return_sequences=False)))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(trainY.shape[1]))\n","\n","    model.compile(optimizer='adam', loss='mse')\n","    \n","    with suppress_stdout():\n","      # fit the model\n","      history = model.fit(trainX, trainY, epochs=30, batch_size=16, validation_split=0.1, verbose=1)\n","      prediction = model.predict(trainX[-(len(df_bilstm)-size):]) #shape = (n, 1) where n is the n_days_for_prediction\n","\n","\n","    prediction_copies = np.repeat(prediction, df_bilstm.shape[1], axis=-1)\n","    y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]\n","    df_bilstm_prdictions=pd.DataFrame(y_pred_future)\n","    df_bilstm_prdictions.index=df_bilstm[size:].index\n","\n","\n","    return df_bilstm_prdictions,history\n","\n","###################################################################################################################################################\n","def format_data_for_future_predictions(df_new,price):\n","  x=int(len(df_new)/4+len(df_new)%4)\n","  for i in range (0,x):\n","    df_new.loc[len(df_new)]=[1,price,0,0]\n","  return df_new\n","\n","\n","###################################################################################################################################################\n","df_temp=pd.DataFrame()\n","def predict(df,plot_graphs=False,training=False,Price=0):\n","  n=len(df)\n","\n","  if training==False:\n","    df=format_data_for_future_predictions(df,Price)\n","\n","  # ARIMA prediction\n","  prediction_test,df_bilstm,prediction_train,test,model=Arima(df)\n","\n","  if plot_graphs==True:\n","    plot_arima(df.products_quantity.to_numpy(),prediction_test,prediction_train)\n","\n","  # BiLSTM correction\n","  df_bilstm_prdictions,history=BiLSTM(df_bilstm)\n","\n","  if plot_graphs==True:\n","    #plot_loss(history)\n","    plot_bilstm(df_bilstm,df_bilstm_prdictions)\n","\n","  # metrics to evaluate the predictions accuracy in case of training.\n","  final_pred=df_bilstm_prdictions[0]+prediction_test\n","  df_temp=metrics(test,prediction_test,df_bilstm_prdictions[0]+prediction_test)\n","\n","  if training==False:\n","    df.drop(df.tail(n).index,inplace = True)\n","  \n","  return final_pred.to_frame(),prediction_test.to_frame(),df_bilstm_prdictions,df_temp,model"]},{"cell_type":"markdown","metadata":{"id":"D23j572wrUYh"},"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMM6R5l09P3I69VKET0EZIi"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}